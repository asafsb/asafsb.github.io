[{"authors":["admin"],"categories":null,"content":"About Software-Defined Coffee is a personal blog started by me, Asaf Blubshtein. This blog will focus mainly on virtualization and VMware solutions, but also home-labs, certifications, and occasionally - coffee.\nMy current role is a Staff Cloud Solution Architect within the VMware Cloud on AWS Customer Success team. In this role, I am responsible for helping customers fulfill their cloud strategy and vision leveraging VMware Cloud on AWS.\nCertifications   \u0026nbsp\u0026nbsp                     Disclaimer The views and opinions expressed on this blog are my own and do not reflect the views and opinions of my employer.\n","date":1622768411,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1622768411,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://softwaredefinedcoffee.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"About Software-Defined Coffee is a personal blog started by me, Asaf Blubshtein. This blog will focus mainly on virtualization and VMware solutions, but also home-labs, certifications, and occasionally - coffee.\nMy current role is a Staff Cloud Solution Architect within the VMware Cloud on AWS Customer Success team. In this role, I am responsible for helping customers fulfill their cloud strategy and vision leveraging VMware Cloud on AWS.\nCertifications   \u0026nbsp\u0026nbsp                     Disclaimer The views and opinions expressed on this blog are my own and do not reflect the views and opinions of my employer.","tags":null,"title":"Asaf Blubshtein","type":"authors"},{"authors":["vcdx"],"categories":null,"content":"Tracks   Data Center Virtualization  Cloud Management \u0026amp; Automation  Desktop and Mobility  Network Virtualization  ","date":1619397839,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1619397839,"objectID":"2c157564b2804affc5627877d9661797","permalink":"https://softwaredefinedcoffee.com/authors/vcdx/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/vcdx/","section":"authors","summary":"Tracks   Data Center Virtualization  Cloud Management \u0026amp; Automation  Desktop and Mobility  Network Virtualization  ","tags":null,"title":"VCDX","type":"authors"},{"authors":["VCDX"],"categories":["VCDX Mocks"],"content":"Service Provider with multiple sites is looking for a vSphere Design, for their management systems (vCenter, DNS, AD, monitoring etc). Due to past experiences with mixed environmentes, they have requested for a 100% virtualized design. This design will focus on one data center currently, but should be easily scaled to other locations wth minimal changes.\nAdditional Information  99.9% uptime for critical monitoring applications Minimize software license costs Easily replicated at other sites Machine to machine traffic should be limited to those machines requiring such traffic   Panelist only information  Source:  2018 VCDX Workshop (Online), originally uploaded to the VCDX Prep Group by  Chris Porter\n","date":1610510502,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610510502,"objectID":"25bdb307cd73a10afa459088e746052f","permalink":"https://softwaredefinedcoffee.com/project/scenario-1/","publishdate":"2021-01-12T22:01:42-06:00","relpermalink":"/project/scenario-1/","section":"project","summary":"Service provider","tags":["VCDX-DCV Mock"],"title":"Scenario 1","type":"project"},{"authors":["VCDX"],"categories":["VCDX Mocks"],"content":"Air Airlines is operating Datacenters in the San Francisco Bay Area, Seattle and Miami. Virtualization ratio is 60%. The company is looking for a solution to virtualize the backend servers hosting their check in and baggage claim applications.\nDue to past experiences with mixed environments, they have requested for a 100% virtualized design. Availability is absolute top priority for Air Airlines. Downtimes must be reduced as much as possible (planned and unplanned).\n Panelist only information Potential guidelines  99.9% uptime for the backend service, even in case of a disaster Applications must scale easily The two applications share a single web front end. Each application has its own application tier and database tier. Due to air traffic security restrictions, access to the infrastructure must be very restricted and secured Design needs to be server and network vendor agnostic   Source:  2018 VCDX Workshop (Online), originally uploaded to the VCDX Prep Group by  Chris Porter\n","date":1610519422,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610519422,"objectID":"723edf26bb43c67e68e5731f57c34fd6","permalink":"https://softwaredefinedcoffee.com/project/scenario-2/","publishdate":"2021-01-13T00:30:22-06:00","relpermalink":"/project/scenario-2/","section":"project","summary":"Air airlines","tags":["VCDX-DCV Mock"],"title":"Scenario 2","type":"project"},{"authors":["VCDX"],"categories":["VCDX Mocks"],"content":"Acme Energy currently has 2 data centers, one in Los Angeles and one in Long Beach. Most of the hardware is EOS/EOL and they would like to build out two new DCs that are farther away from one another. They want to keep the existing facility in L.A., build the second one in Dallas, and decommission the one in Long Beach within 6 months.\n","date":1610520777,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610520777,"objectID":"27f1cbf143c0dfed7fffb160a4620524","permalink":"https://softwaredefinedcoffee.com/project/scenario-3/","publishdate":"2021-01-13T00:52:57-06:00","relpermalink":"/project/scenario-3/","section":"project","summary":"Acme Energy","tags":["VCDX-DCV Mock","VCDX-NV Mock"],"title":"Scenario 3","type":"project"},{"authors":["VCDX"],"categories":["VCDX Mocks"],"content":"Empire industries is an international corporation providing multiple services\n","date":1611039177,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611039177,"objectID":"0e19eeee4c2625a61c03d1ac01ebfa1d","permalink":"https://softwaredefinedcoffee.com/project/scenario-4/","publishdate":"2021-01-19T00:52:57-06:00","relpermalink":"/project/scenario-4/","section":"project","summary":"Empire Industries","tags":["VCDX-DCV Mock"],"title":"Scenario 3","type":"project"},{"authors":["Asaf Blubshtein"],"categories":["HCX"],"content":"HCX 4.0 introduced plenty of new  features and functionalities, such as migration details and security tag migrations to name a few. One of the features I like the most is In-Service Upgrade for the network extension appliance(s). While the standard upgrade re-deploys the network extension (NE) appliance, the in-service upgrade will deploy an extra appliance with a new set of IPs prior to removing the old appliance. This will allow HCX to establish a tunnel between the two new appliances and then do a switchover to minimize downtime for the extended networks.\nTo compare the downtime the extended networks experience using each upgrade methods, I tested the impact of each one on the connectivity between two VMs while redeploying the NE appliances. You can read about the steps I performed or jump straight to the test conclusion:\n  Test Environment Overview  Standard Upgrade  In-Service Upgrade  Conclusion   This test was performed in my lab environment, so the actual results in other environments may vary   Test Environment Overview   To perform the test I am using my home lab, located in Chicago, and a VMware Cloud on AWS SDDC in Oregon (us-west-2). Both sites are connected via route-based VPN and have HCX deployed and a service mesh configured:   A single network, site1-vlan11, is extended between the sites. The CIDR range is 172.25.11.0/24 and my lab\u0026rsquo;s pfSense functions as the default gateway for the network. The pfSense is also the default gateway of the other network I\u0026rsquo;m using, core-vlan10 which uses CIDR 172.25.10.0/24   The following VMs were used to test the connectivity:\n   Name Location Portgroup IP Address OS     core-mint On-prem core-vlan10 172.25.10.212 Linux Mint   sdcoffee-vlan11 VMW on AWS L2E_site1-vlan11-11-189c7e98 172.25.11.236 Photon OS      Before running the tests, the NE appliance on-prem is deployed with the following IPs:\n   Traffic type IP     Management Network 172.25.10.22   Uplink Network 192.168.1.222      To simulate the process that occurs during an appliance upgrade I opted to redeploy the appliances, as this gives me the option of running the test several times without needing to wait for a new version to upgrade to. To redeploy the appliances, follow these steps:\n Open to the HCX plugin or connect to the HCX manager Select Interconnect and then the Service Mesh tab Under the service mesh you\u0026rsquo;d like to test, click View Appliances Select the NE appliance and click Redeploy You\u0026rsquo;d then have the option of selecting Standard or In-Service mode' Once the redeployment is initiated, the tasks can be viewed from the Tasks tab    Standard Upgrade Before redeploying the NE appliance I launched the following ping command from core-mint, which provides a timestamp and will also show failed ping packets:\nping -i 1 -O 172.25.11.236 | ts \u0026quot;%H:%M:%.S\u0026quot;  Next, I redeployed the NE appliance using Standard mode:\nDuring the redeployment process, a new NE appliance will be deployed in both the source and destination sites. In this screenshot, we can see that a new NE appliance is deployed on-prem with the same IPs as the original appliance:\n  After a couple of minutes, HCX will start configuring the connectivity between the two new NE appliances:\n  During this step, the tunnel is being established between the two appliances, which means downtime for the extended networks. In my environment the VMs lost connectivity for a little under 25 seconds:\n  Once the tunnel is up and running HCX will remove the original appliances and will rename them.\nIn-Service Upgrade Similar to the steps performed in the standard mode test, I started a continuous timestamped ping from core-mint. However, when running the same command as I did previously for the first couple of tests I did not see any loss of packets (which is very promising!). Because of that, I changed the ping frequency to 200ms, which is the minimum possible:\nping -i 0.2 -O 172.25.11.236 | ts \u0026quot;%H:%M:%.S\u0026quot;  Next, I redeployed the NE appliance using In-Service mode:\nOnce again, a new NE appliance will be deployed in both the source and destination sites. This time, as seen in the screenshot of the on-prem environment, the new NE appliance is deployed using a different set of IPs:\n  As a comparison, here are the IPs of the original and newly deployed NE appliances:\n   Interface Original NE Appliance New NE Appliance     Management IP 172.25.10.22 172.25.10.24   Uplink IP 192.168.1.222 192.168.1.224    Since In-Service is using a new set of appliances with different IP addresses the tunnel configuration between them doesn\u0026rsquo;t impact existing traffic. Instead, workloads are only experiencing a short amount of downtime during a new step, the NetExt Switchover:\n  Before this step, there are two sets of appliances with a tunnel established between them. During this step, the network extensions are switched over to the tunnel between the two new appliances. In my environment the VMs lost connectivity for just a little more than a second:\n  Again, once the extensions are switched over to the new appliances HCX will remove the original appliances and rename them.\nConclusion Here is the summary of the results I got in the tests of the two upgrade/redeployment modes:\n   Metric Standard Mode In-Service Mode     Network Downtime 24.55 Seconds 1.02 Seconds   Preparation None Required - Additional IP per NE appliance upgraded/redeployed - Service mesh must be in a healthy state - HCX 4.0 and above    Just as a reminder, this was tested in my lab environment so your mileage may vary. That being said, the difference between the two modes is quite significant. While 25 seconds will definitely impact applications, most shouldn\u0026rsquo;t even notice a 1 second outage, which is similar to what is experienced during vMotion.\nSince most of the downtime the HCX extended networks experience is planned due to upgrades, In-Service mode can significantly improve the availability of workloads connected to extended networks.\n","date":1622768411,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622768411,"objectID":"92058d249c09cf0e2bef14ee9419363a","permalink":"https://softwaredefinedcoffee.com/post/2021-06-04-testing-in-service-upgrade-for-hcx-network-extension-appliances/","publishdate":"2021-06-04T01:00:11Z","relpermalink":"/post/2021-06-04-testing-in-service-upgrade-for-hcx-network-extension-appliances/","section":"post","summary":"HCX 4.0 introduced plenty of new  features and functionalities, such as migration details and security tag migrations to name a few. One of the features I like the most is In-Service Upgrade for the network extension appliance(s). While the standard upgrade re-deploys the network extension (NE) appliance, the in-service upgrade will deploy an extra appliance with a new set of IPs prior to removing the old appliance. This will allow HCX to establish a tunnel between the two new appliances and then do a switchover to minimize downtime for the extended networks.\nTo compare the downtime the extended networks experience using each upgrade methods, I tested the impact of each one on the connectivity between two VMs while redeploying the NE appliances.","tags":["HCX"],"title":"Testing In-Service Upgrade for HCX Network Extension Appliances","type":"post"},{"authors":["Asaf Blubshtein"],"categories":["VMware Cloud on AWS","Networking"],"content":"For certain tests and demos, I occasionally need to connect my home lab to our VMW on AWS SDDC. Since I can\u0026rsquo;t justify the cost of a Direct Connect port to my home lab my options are either route or policy-based VPN. Unless there\u0026rsquo;s a specific use-case for policy-based, route-based VPN (RBVPN) is definitely  my preferred method.\nCurrently, I\u0026rsquo;m using a pfSense router/firewall for my home lab, which meant the first step was to select which BGP package I should install. At first, I was going to configure BGP using OpenBGPD as it seemed more common, but I decided to use FRR instead. The main reason was that at the time I was also studying for the NSX-V VCAP Deploy exam and wanted to be able to leverage both OSPF and BGP. Another reason was that it seems as though FRR is being recommended over OpenBGPD and Quagga OSPF as pfSense\u0026rsquo;s dynamic routing package of choice.\nPlanning and Pre-requisites  There are certain values in a RBVPN that have to be identical in both sites and some that must be different for connectivity to work:     Setting/Value Description Values I used     Local public IP The public IP associated with the pfSense. If it\u0026rsquo;s behind a NAT, note the private IP as well  My public IP and 192.168.1.254   Remote public IP The VPN Public IP of the SDDC    Local BGP ASN The ASN that will be assigned to pfSense 65025   SDDC BGP ASN The ASN that will be assigned to the SDDC\u0026rsquo;s BGP instance. Must be different than the local BGP ASN 65001   IPsec IKE version (for phase 1 and 2) Select a setting that is  supported by VMW on AWS. The setting must be identical in both sites for an IPsec session to establish IKEv2   IPsec encryption parameters (for phase 1 and 2) Select values that are  supported by VMW on AWS. Values must be identical in both sites for an IPsec session to establish AES GCM 256, 128-bit key, SHA256, DH14   Pre-shared key for IPsec Will be used to authenticate the IPsec session between pfSense and the SDDC Generated using pfSense   Local BGP IP An IP in a network that will only be used to establish a BGP neighbor relationship between pfSense and the SDDC. Doesn\u0026rsquo;t need to be large or routable, preferably in the 169.254.0.0 range 169.254.225.25/30   SDDC BGP IP An IP in the same subnet as the local BGP IP 169.254.225.26/30     Configure port forwarding (Optional) - If your pfSense is not directly connected to the internet you\u0026rsquo;ll need to enable port forwarding in your public-facing router/firewall and forward UDP port 4500 to your pfSense\u0026rsquo;s private IP  In VMW on AWS:  Note the VPN public IP - In the SDDC you\u0026rsquo;d like to connect to, navigate to the Networking \u0026amp; Security section. The Overview tab should have the VPN Public IP listed:   Note/change the VMW on AWS ASN - The default ASN is 65000. To validate or edit the ASN, within the Networking \u0026amp; Security section, navigate to VPN \u0026gt; Route Based. Click Edit Local ASN. You can now change the number to an ASN that is unique in your BGP environment. In this configuration I will use 65001.  In pfSense:  Allow APIPA traffic (optional) - By default VMW on AWS allows RBVPN BGP sessions to be formed using the 169.254.0.0/16 range. pfSense drops that range by default. To configure pfSense to allow that range navigate to System \u0026gt; Advanced. Go to the Firewall \u0026amp; NAT tab and check Allow APIPA traffic. If APIPA traffic is not allowed the range that will be used for the BGP session should be permitted in the Compute Gateway firewall in VMW on AWS.   Install FRR - FRR will add dynamic routing capabilities to pfSense using BGP and OSPF. To install FRR navigate to System \u0026gt; Package Manager and select the Available Packages tab. Search for FRR and click Install. Once the installation is finished successfully FRR will appear under Installed Packages.  pfSense configuration Step 1 - Conigure IPsec Tunnel\n Navigate to VPN \u0026gt; IPsec and click Add P1 Configure the following phase 1 settings (these settings will have to match when configured in VMW on AWS):  Key Exchange version - IKEv1 or IKEv2. I selected IKEv2 Interface - the WAN interface of your pfSense Remote Gateway - the VPN Public IP of the SDDC Pre-Shared Key - enter a shared key or generate one Encryption Algorithm - select encryption the desired values that are  supported by VMW on AWS. I selected the following:  Algorithm - AES256-GCM Key length - 128 Hash - SHA256 DH Group - 14 (2048 bit)     On the newly created IPsec tunnel, Click Show Phase 2 Entries and then Add P2 Configure the following phase 2 settings:  Mode - Routed (VTI) Local Network - Address (not Network!). Under Address enter the local BGP IP designated for pfSense. I used 169.254.225.25 Remote Network - Address (not Network!). Under Address enter the remote BGP IP designated for VMWonAWS. I used 169.254.225.26 Similar to the encryption configuration in Phase 1, select encryption values that are  supported by VMW on AWS. I selected similar values to the ones I set in Phase 1:  Algorithm - AES256-GCM Key length - 128 Hash - SHA256 PFS Key Group - 14 (2048 bit)     Validate both Phase 1 and Phase 2 configurations and click Apply Changes    Step 2 - Assign the IPsec interface. This step enables the IPsec tunnel created in the previous step as a virtual interface for pfSense, so it can be leveraged by FRR to establish a BGP connection.\n Navigate to Interfaces \u0026gt; Assignments At the bottom, under Available network ports, select the newly created IPsec tunnel and click Add   The new interface is added as OPT#. In my case it was added as OPT4. Click the interface name Check Enable Interface and provide a Description to make it easier to identify the interface Click Save  Step 3 - Allow traffic via the IPsec interface. By default pfSense will block any traffic on newly added interfaces. For the BGP connection to establish and for traffic to flow several allow rules should be opened.\n Navigate to Firewall \u0026gt; Rules Select the IPsec interfaces Create inbound and outbound rules that will match the traffic you want to allow communicating over the RBVPN. Don\u0026rsquo;t forget to also enable the BGP communication between pfSense and the SDDC. For this scenario I\u0026rsquo;m going to allow all traffic  Step 4 - Configure FRR. Now that IPsec is configured on the pfSense side, we are ready to configure FRR and BGP.\n Navigate to Services \u0026gt; FRR Global/Zebra Check Enable FRR Set the Default Router ID. You can specify it individually per routing protocol. I set it to the pfSense\u0026rsquo;s BGP IP, 169.254.225.25 Set a Master Password. This password is only used by FRRs internal daemons, so set it to whatever you want Click Save  Step 5 - Configure FRR\u0026rsquo;s BGP. Note that I\u0026rsquo;m not going into the (many) configuration options possible in BGP. This is just going to be a minimal setup to enable communication and route exchanges.\n Navigate to Services \u0026gt; FRR BGP Check Enable BGP Routing Set the Local AS to a value that is different than the AS in VMW on AWS. In my lab it is set to 65025 Specify the Router ID if you\u0026rsquo;d like it to be different than the one specified in step 4   Under Network Distribution, you can control what routes are advertised via BGP. Since I didn\u0026rsquo;t want all of my lab and home subnets to be advertised, I decided to specify the ones I wanted to use for testing purposes Click Save  Step 6 - Configure the SDDC\u0026rsquo;s Edge as a BGP neighbor. Similar to the previous step, there\u0026rsquo;s a lot of BGP options here, but I\u0026rsquo;m just going to cover the basic to establish connectivity.\n In the FRR BGP view, select the Neighbors tab and click Add Under Name/Address set the remote BGP IP of the SDDC. In my case it\u0026rsquo;s 169.254.225.26 Set a Description to easily identify this neighbor Set the Remote AS to the ASN configured in VMW on AWS Click Save  VMW on AWS configuration Step 7 - Configure RBVPN in VMW on AWS\n Navigate to Networking \u0026amp; Security \u0026gt; VPN. By default you should be in the Route Based tab Click Add VPN Configure the following in the top section:  Name - Descriptive name to identify the VPN Local IP Address - Select the Public IP from the drop down list. Note: this cannot be changed later Remote Public IP Address - The public IP where the pfSense is reachable BGP Local IP/Prefix Length - Enter the SDDC\u0026rsquo;s BGP IP and prefex length. I used 169.254.225.26/30. Note: this cannot be changed later BGP Remote IP - Enter the pfSense BGP IP. I used 169.254.225.25. Note: this cannot be changed later BGP Neighbor ASN - Enter the ASN configured in pfSense. I used 65025 Preshared Key - Enter the same pre-shared key entered in step 1 Remote Private IP - If the pfSense is behind a NAT, enter the private IP of the pfSense. I used 192.168.1.254, which is the WAN interface   Configure the following in the bottom section (all values should correlate to the IPsec config in step 1):  IKE Encryption - Correlates to pfSense\u0026rsquo;s Phase 1 algorithm. I configured AES GCM 256 IKE Digest Algorithm - Correlates to pfSense\u0026rsquo;s Phase 1 hash. I configured None, as this is required in VMWonAWS  when using GCM IKE Type - Correlates to pfSense\u0026rsquo;s Phase 1 key exchange version. I configured IKE V2 Diffie Hellman - Correlates to pfSense\u0026rsquo;s Phase 1 DH Group. I configured 14 Tunnel Encryption - Correlates to pfSense\u0026rsquo;s Phase 2 algorithm. I configured AES GCM 256 Tunnel Digest Algorithm - Correlates to pfSense\u0026rsquo;s Phase 2 hash. I configured None, as this is required in VMWonAWS  when using GCM Perfect Forward Secrecy - Correlates to pfSense\u0026rsquo;s Phase 2 PFS. I set it to Enabled   Click Save    Step 8 (Optional) - Allow the BGP IPs in the Gateway Firewall if a they are not in the 169.254.0.0/16 range\n Navigate to Networking \u0026amp; Security \u0026gt; Gateway Firewall. By default you should be in the Compute Gateway tab Click + Add Rule Make sure the Sources and Destination are the subnet/IPs that are used by both BGP interfaces. Under Applied To apply the rule only to the VPN Tunnel Interface Click Publish  Validate Connectivity At this point the IPsec tunnels should be up and the BGP session should establish and extend routes. We can validate connectivity in VMWonAWS and in pfSense.\nIn VMW on AWS - navigate to Networking \u0026amp; Security \u0026gt; VPN. In the Route Based tab verify that both the Status and BGP Remote IP are showing a green circle. You can also expand the view and view the learned and advertised routes.\nIn pfSense - navigate to Status \u0026gt; FRR. In the BGP tab there are several places where you can validate the established connection. The main ones are:\n Under the BGP Routes you can view the learned routes BGP Neighbors will present a lot of information about the neighbor connection. The important thing is to make sure the BGP State is Established  ","date":1621386011,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621386011,"objectID":"ccc0c615abb0f9d67ef647035b5e4028","permalink":"https://softwaredefinedcoffee.com/post/2021-05-19-configuring-route-based-vpn-between-vmware-cloud-on-aws-and-pfsense/","publishdate":"2021-05-19T01:00:11Z","relpermalink":"/post/2021-05-19-configuring-route-based-vpn-between-vmware-cloud-on-aws-and-pfsense/","section":"post","summary":"For certain tests and demos, I occasionally need to connect my home lab to our VMW on AWS SDDC. Since I can\u0026rsquo;t justify the cost of a Direct Connect port to my home lab my options are either route or policy-based VPN. Unless there\u0026rsquo;s a specific use-case for policy-based, route-based VPN (RBVPN) is definitely  my preferred method.\nCurrently, I\u0026rsquo;m using a pfSense router/firewall for my home lab, which meant the first step was to select which BGP package I should install. At first, I was going to configure BGP using OpenBGPD as it seemed more common, but I decided to use FRR instead.","tags":["VMC on AWS","VMWonAWS","VMware Cloud on AWS","pfSense","VPN","RBVPN","Route Based VPN"],"title":"Configuring Route Based VPN Between VMware Cloud on AWS and pfSense","type":"post"},{"authors":["VCDX"],"categories":["VCDX","Mentorship"],"content":"The Mentor\u0026rsquo;s Role The mentor will provide guidance through the candidate\u0026rsquo;s VCDX journey. It is the candidate\u0026rsquo;s responsibility to take ownership of the process and perform the required work and research to create their design, documentation, submission, and prepare for their defense.\nVCDX Mentorship Experience  Once a mentorship request has been submitted, please allow up to two weeks for mentors to respond. If you still haven\u0026rsquo;t received a response, please email  vcdx.mentorship@gmail.com The mentors may not answer all of your questions, but will direct you to resources that can help you find the answers so you can understand the decision and the processes While the mentor can help you plan and review your VCDX timeline to submission it is still your responsibility to make sure you are on-track and keeping up with your tasks The VCDX mentors most likely have very demanding roles. Understand that the mentor will have limited time available for reoccuring meetings. Discuss availability with your mentor and consider engaging multiple mentors as well  I understand that the mentor will not:  Share the design or documentation they submitted/created for their application Provide any information about the questions they were asked during their design defense Provide any information about the design scenario the had to address during their defense Help build the design or influence its overall direction Do a deep review of the application documents Add or remove specifics to the design Take owenership of the design/submission  ","date":1619397839,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619397839,"objectID":"6e8e43d099de387f139b84b16fac9cde","permalink":"https://softwaredefinedcoffee.com/vcdx/mentoring-policy/","publishdate":"2021-04-25T19:43:59-05:00","relpermalink":"/vcdx/mentoring-policy/","section":"vcdx","summary":"The Mentor\u0026rsquo;s Role The mentor will provide guidance through the candidate\u0026rsquo;s VCDX journey. It is the candidate\u0026rsquo;s responsibility to take ownership of the process and perform the required work and research to create their design, documentation, submission, and prepare for their defense.\nVCDX Mentorship Experience  Once a mentorship request has been submitted, please allow up to two weeks for mentors to respond. If you still haven\u0026rsquo;t received a response, please email  vcdx.mentorship@gmail.com The mentors may not answer all of your questions, but will direct you to resources that can help you find the answers so you can understand the decision and the processes While the mentor can help you plan and review your VCDX timeline to submission it is still your responsibility to make sure you are on-track and keeping up with your tasks The VCDX mentors most likely have very demanding roles.","tags":["VCDX","Mentoring"],"title":"VCDX Mentoring Policy","type":"vcdx"},{"authors":["Asaf Blubshtein"],"categories":["VMware Cloud on AWS","PowerShell","Storage"],"content":"Stretched Clusters provide the ability to protect an SDDC running in VMware Cloud on AWS from an Availability Zone failure. If you would like to know more about the Stretched Clusters capability, sometimes referred to as Multi AZ SDDCs in VMW on AWS, make sure you read  this article by  Emad Younis,  this post by  Frank Denneman and  this article by  Glenn Sizemore. In addition,  as announced in December 2019, there is a 95% discount on the cross-AZ traffic between the AZs.\nJust like a standard vSAN cluster, storage consumption in a Stretched Cluster is managed using storage policies. The Failures to tolerate settings defines how data is placed in a single AZ, e.g. RAID1 FTT1, while Site disaster tolerance configures how data is placed across the AZs. The workload can either be mirrored across sites or set to a specific site (preferred or non-preferred) with no cross-site protection. Logically, most workloads in a Stretched Cluster will be protected across both sites. However, there may be some cases where vSAN cross-AZ protection is unnecessary, such as workloads that already offer application level redundancy.\nOne aspect that is sometimes overlooked is that the storage policies only handle data placement while the placement of compute is handled by DRS. By default, DRS has no awareness of where the storage of a specific workload resides and whether it\u0026rsquo;s replicated across the sites. This can result in a misalignment of the data and compute placement. For example, the storage policy can configure data to be placed in the preferred site while DRS places or moves the VM to a host in the non-preferred one. Another potential scenario is a clustered application that can have both instances running on hosts in the same AZ which increases recovery time in case of an AZ failure.\nOn-prem, DRS affinity rules are leveraged to make DRS aware of vSAN storage placement. In VMW on AWS the same outcome can be achieved using tags and  Compute Policies. Basically, two VM-Host compute policies should be created – one for the preferred site and on for the non-preferred site. After that all the hosts in the corresponding fault-domains will need to be tagged. In addition, every time a host is added to the cluster it will need to be tagged otherwise no VMs from these compute policies will be running on the new host. It is possible to create the compute policies manually and then tag all the hosts, but to make the process easier and faster I created a PowerShell module named  MultiAZTagging.psm1 to create the policies and tag the hosts.\nPowerShell Module Review The module contains two cmdlets:\n New-MultiAzTags - Creates a tag category, tags and compute policies for the preferred and non-preferred sites. By default, all the objects created are prepended with “MultiAZ”. A different string can be specified using the TagCategoryName parameter. Set-MultiAzHostTag – Assigns the appropriate tags to hosts in the cluster. A specific host or cluster can be specified, using either HostName or ClusterName, otherwise all the hosts in the SDDC will be tagged. If the right tag exists on the host no action is taken. In case a different value other than “MultiAZ” was used to create the tags it should be specified using the TagCategoryName parameter.  Using the MultiAZ Tagging Module Before I step into how to run the script, I wanted to give you a quick recap of the environment I\u0026rsquo;m going to run it on. This is stretched cluster SDDC deployed across two AZs in Oregon (us-west-2). The AZs are us-west-2a and us-west-2b (preferred fault domain):\nThere’s two VMs in the cluster, az1 and az2. At the moment they both run on a host in us-west-2b, which is the preferred site:\nStep 1 -  Download the PowerShell module\nStep 2 - Import the PowerShell module\nImport-Module .\\MultiAZTagging.psm1  Step 3 - Connect to a vCenter in a Stretched Cluster SDDC using Connect-VIServer\nStep 4 - Connect to the same vCenter using Connect-CisServer (this step is required to create the compute policies)\nStep 5 - Run the New-MultiAZTags command to create the tag category, tags and compute policies\nAs shown by the command\u0026rsquo;s output, the following were created:\n A tag category with the name MultiAZ. Only one tag from this category can be assigned to a single host or VM   Two tags in the MultiAZ tag category - MultiAZ-Preferred and MultiAZ-Non-Preferred. The description of each tag specifies the AZ for that site   Two compute policies named MultiAZ-Preferred and MultiAZ-Non-Preferred. Each policy is a VM-Host affinity policy which requires the hosts and VMs to be tagged using the matching tags created previously. Note that there are zero hosts/VMs matching this policy as no host/VM has any of the tags assigned  Step 6 – Run the Set-MultiAzHostTag command to tag all the hosts in the SDDC\n As the command\u0026rsquo;s output shows, each host was assigned a tag that matches their fault domain   In addition, the compute policies now show that each policy has a single host with a matching tag  Step-7 – Assign tags to the appropriate VMs. This can be done manually via the GUI or by using the New-TagAssignment PowerCLI command.\n In my environment I tagged VM az1 with the MultiAZ-Preferred tag and VM az2 with the MultiAZ-Non-Preferred tag. Following that both compute policies now show one associated VM in addition to the host   A couple of seconds after I assigned the MultiAZ-Non-Preferred tag to the az2 VM DRS initiated a migration to the host in the non-preferred fault domain  As I mentioned before, there are several use cases I can think of for pinning a VM to a specific site. The most obvious one is a VM that is not replicated across AZs, so it makes sense to have the VM running in the same AZ. The second one is a resilient application, such as AD Domain Controllers, where making sure at least one node is always running. The great thing about compute policies is that they leverage a ‘should’ rule. That means that if an entire AZ fails, for example the non-preferred one, if the VM data is replicated the VMs set to the MultiAZ-non-preferred compute policy will still be powered on the preferred site by vSphere HA. Once the non-preferred AZ comes back up DRS will migrate the VMs to hosts the adhere to the compute policy.\nI hope that you find this PowerShell module useful and that it can help address some design requirements in your SDDC. At the moment, in order to tag new hosts that are added to the SDDC using eDRS or as a planned procedure, you’ll need to run Set-MultiAzHostTag again. Since it skips existing hosts you can also run it on a schedule. In the next couple of weeks, I’m planning on testing integration of the Set-MultiAzHostTag with  VEBA, so it can be run when a new host is added to the SDDC.\n","date":1594950250,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594950250,"objectID":"bd64a97b3c58fb8504621266609925f0","permalink":"https://softwaredefinedcoffee.com/post/2020-07-16-powershell-module-to-manage-workload-placement-in-vmwonaws-stretched-clusters/","publishdate":"2020-07-16T20:44:10-05:00","relpermalink":"/post/2020-07-16-powershell-module-to-manage-workload-placement-in-vmwonaws-stretched-clusters/","section":"post","summary":"Stretched Clusters provide the ability to protect an SDDC running in VMware Cloud on AWS from an Availability Zone failure. If you would like to know more about the Stretched Clusters capability, sometimes referred to as Multi AZ SDDCs in VMW on AWS, make sure you read  this article by  Emad Younis,  this post by  Frank Denneman and  this article by  Glenn Sizemore. In addition,  as announced in December 2019, there is a 95% discount on the cross-AZ traffic between the AZs.\nJust like a standard vSAN cluster, storage consumption in a Stretched Cluster is managed using storage policies.","tags":["VMC on AWS","VMWonAWS","VMware Cloud on AWS","PowerShell","vSAN","Stretched Cluster"],"title":"PowerShell Module to Manage Workload Placement in VMware Cloud on AWS Stretched Clusters","type":"post"},{"authors":null,"categories":null,"content":"Who we are The website address is https://softwaredefinedcoffee.com, owned by Asaf Blubshtein.\nComments This website uses a comment system powered by  GraphComment, a company based out of Paris, France. The system doesn’t collect the names of the visitors who leave comments on the site and they remain anonymous in analytics. You can refer to the provider’s  privacy policy for more information.\nGoogle Analytics This website uses  Google Analytics to collect information required to analyze the traffic of this site. For each visitor to reach the site, Google Analytics collects the following non-personally identifiable information, including but not limited to browser type, version and language, operating system, pages viewed while browsing the site, page access times and referring website address. This information is presented to me as aggregated reports.\nI have set the  Hugo GDPR options so that your IP address is anonymised within Google Analytics and the “Do Not Track” request is respected. For more information, please refer to Google Analytics  data privacy and security policy. You may opt-out to Google Analytics service by visiting  this page.\nMedia If you upload images to the website, you should avoid uploading images with embedded location data (EXIF GPS) included. Visitors to the website can download and extract any location data from images on the website.\nEmbedded content from other websites Articles on this site may include embedded content (e.g. videos, images, articles, etc.). Embedded content from other websites behaves in the exact same way as if the visitor has visited the other website.\n","date":1592262000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592262000,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"https://softwaredefinedcoffee.com/privacy/","publishdate":"2020-06-16T00:00:00+01:00","relpermalink":"/privacy/","section":"","summary":"Who we are The website address is https://softwaredefinedcoffee.com, owned by Asaf Blubshtein.\nComments This website uses a comment system powered by  GraphComment, a company based out of Paris, France. The system doesn’t collect the names of the visitors who leave comments on the site and they remain anonymous in analytics. You can refer to the provider’s  privacy policy for more information.\nGoogle Analytics This website uses  Google Analytics to collect information required to analyze the traffic of this site. For each visitor to reach the site, Google Analytics collects the following non-personally identifiable information, including but not limited to browser type, version and language, operating system, pages viewed while browsing the site, page access times and referring website address.","tags":null,"title":"Privacy Policy","type":"page"},{"authors":["Asaf Blubshtein"],"categories":["VMware Cloud on AWS","Networking"],"content":"When we assist customers in designing a new VMware Cloud on AWS SDDC the question of Layer 2 extension comes up frequently. The reasons to extend on-prem networks are unique to each environment and can be a temporary state during migration or a long term strategy to ease scalability and bursting to the cloud.\nVMW on AWS provides two options for extending an on-prem network to the SDDC - HCX Network Extension (NE) and Layer 2 VPN. While both solutions provide the same functionality they are different in several aspects. I won’t go into a detailed comparison in this post, but most users, especially if they are not very familiar with networking, will find that HCX NE is easier to configure and scale. L2 VPN, on the other hand, will provide faster recoverability from an appliance failure, and depending on how many networks are extended, it may use less compute resources on-prem and in the SDDC.\nSince version 1.9 of VMW on AWS, the NSX-T 2.5 Autonomous Edge is used, which is simpler to configure and more performant than the previous L2 VPN client. In this post I will demonstrate how to configure the HA functionality for the autonomous edge.\nWhen configuring a highly avaialable autonomous edge two appliances are deployed. The first edge that is deployed is the Primary edge and the second one is the Secondary edge. The Primary/Secondary value is permanent and simply indicates which edge was deployed first. It doesn\u0026rsquo;t represent which edge is active and handling the L2 VPN. This is shown by Active/Standby high availability status in the summary dashboard.\nDeploying the Primary Autonomous Edge and Configuring L2 VPN My colleague, David Zhang, wrote a great post explaining all the necessary steps to deploy L2 VPN on VMW on AWS using the autonomous edge. I followed David\u0026rsquo;s guide to configure L2 VPN and used the following values to set up the primary autonomous edge:\n Management IP - 192.168.1.240 External Port  Port – 0,eth1,192.168.1.241,24 GW – 192.168.1.254   Internal - left blank HA  Port – 0,eth3,172.25.53.1,24 GW – 172.25.53.254 Do not fill any other values in the HA section    The L2 VPN tunnel and network extensions can be created before or after the secondary edge is deployed. There is no significance to the order in which these actions are performed.\nDeploying the Secondary Autonomous Edge Step 1 - Deploy the autonomous edge OVF. Make sure the exact same edge size (medium or large) and networks as the primary controller are selected.\nStep 2 - Under network properties, enter the hostname, default gateway, management IP and netmask. Make sure the same subnet as the management network of the primary edge is entered. I used 192.168.1.242:\nStep 3 - The external IP of the secondary edge can be blank. After powering on the appliance it will negotiate with the primary edge and the same external IP as the primary edge will be configured in a disconnected state. As with the primary edge the internal port should be blank:\nStep 4 - Configure the HA port\n Port – 0,eth3,172.25.53.2,24 This port should be in the same subnet as the HA port of the primary edge Default GW – 172.25.53.254 Check the Secondary API Node checkbox Primary node IP – 192.168.1.240 This is the management IP of the primary edge deployed previously Primary Node Credentials – If you changed the default username of the primay edge make sure you enter that username. Otherwise, it\u0026rsquo;s admin Primary node thumbprint – To get the API thumbprint log in to the primary edge with the admin user and type the following command:\n get certificate api thumbprint  Step 5 - Make sure the edge VMs are running on different hosts and migrate one if necessary. If DRS is configured on the cluster create a rule to separate the edges.\nValidating The Secondary Edge Deployment A couple of minutes after the secondary edge powered on login to both appliances to validate the High Availability status. Under HA Peer Address, each edge should list the opposite edge’s management IP as a peer.\nNote – for some reason the management and peer addresses list a subnet mask of /19 on the web interface even though the correct mask of /24 is configured.\nThe primary edge should have a Primary API server role and an Active HA status. Once the L2 VPN is configured its status will be Up:\nThe secondary edge should have a Secondary API server role and Standby under HA status. Once the L2 VPN is configured its status will be Doen:\nIn the Port tab you can see that both edges have port named lrport_0 with the same IP and Port ID. The GUI doesn\u0026rsquo;t indicate what is the status of the port but this can be found using CLI. To do so login to both edges with the admin user and type the command get logical-router interfaces and find the port named lrport_0. You can also type get logical-router interface \u0026lt;port id\u0026gt;. The admin state of both ports should be up but the op_state of the standby edge should be down.\nCommand output of the Active edge: Command output of the Standby edge: Autonomous Edge HA Failover Test To test the autonomous edge failover, I initiated a continuous ping with timestamp to a VM connected to an extended L2 network in the VMW on AWS SDDC. After about 30 seconds to verify there are no drops, I powered off the active edge. The connection did drop but as can be seen in the screenshot below the standby edge claimed the external IP and re-established the L2 VPN tunnel in 10 seconds:\nAfter powering on the powered-off edge the HA status between the edges was re-established. The secondary edge remains the active edge and the primary will become active again only in case of an additional failure.\nSecondary edge status:\nPrimary edge status:\n","date":1589512636,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589512636,"objectID":"f07bb58df61465edeb1781c145bb34d3","permalink":"https://softwaredefinedcoffee.com/post/2020-05-14-configuring-l2vpn-high-availability-in-vmw-on-aws/","publishdate":"2020-05-14T22:17:16-05:00","relpermalink":"/post/2020-05-14-configuring-l2vpn-high-availability-in-vmw-on-aws/","section":"post","summary":"When we assist customers in designing a new VMware Cloud on AWS SDDC the question of Layer 2 extension comes up frequently. The reasons to extend on-prem networks are unique to each environment and can be a temporary state during migration or a long term strategy to ease scalability and bursting to the cloud.\nVMW on AWS provides two options for extending an on-prem network to the SDDC - HCX Network Extension (NE) and Layer 2 VPN. While both solutions provide the same functionality they are different in several aspects. I won’t go into a detailed comparison in this post, but most users, especially if they are not very familiar with networking, will find that HCX NE is easier to configure and scale.","tags":["VMC on AWS","VMWonAWS","VMware Cloud on AWS","L2VPN","Networking"],"title":"Configuring L2VPN High Availability in VMware Cloud on AWS","type":"post"},{"authors":["Asaf Blubshtein"],"categories":["Work From Home","Business Travel"],"content":"As more people are working from home due to COVID-19, I’ve seen plenty of remote-working resources and tips being shared across social media and other platforms. The Virtually Speaking Podcast did a great episode about it recently. Most of these resources discuss the changes both the employee and employer must make regarding communication, productivity, and culture change. If you are not accustomed to working remotely, then maintaining visual communication and avoiding distractions will take time to get used to and incorporate into your daily routine. While these skills are extremely important and can feel overwhelming when you are thrown into the situation on short notice, it is also essential to keep basic ergonomics in mind.\nIf you’re working from home temporarily, you’ll most likely be using your laptop, possibly while sitting on the sofa or bed. Using a laptop this way for an hour or two to answer some emails may be OK, but spending an entire workday like that can be an issue. I’m not an ergonomics expert, but I do know that the basics are keeping the monitor at eye level and the mouse and keyboard at a position that will allow your forearms to be as parallel to the floor as possible. The way laptops are designed forces you to bend your back and neck which, over time, will cause fatigue and discomfort.\nI’ve been working remotely for about five years, so I’ve had a lot of time to fine-tune my home office setup. Some of it was provided by my employer (external monitor, docking station) and some were purchased by me throughout the years (chair, desk, ergonomic keyboard and mouse). If your employer can provide you with some equipment or if you already have a home office setup - great. If you don’t, hopefully I can share some tips that will help you improve your temporary home office experience.\nEven though I’m working remotely, travel has always been a big part of my current and previous roles. Whether it was visiting a customer, attending a training, or meetings at the company HQ, I’d find myself working solely with a laptop for longer than I’d prefer. Starting with purchasing an external mouse, I eventually acquired enough items to travel with a complete mobile office. This setup is lightweight, doesn’t take up a lot of space, and doesn’t break the bank. If you travel for work, you’ll also be able to repurpose it for that in the future. Here’s my travel setup sitting on my dining room table (which to be completely honest, functions as my desk when we have too many guests staying over): 1. Coffee I mean, can you really work without it?!\n2. Laptop Stand This is a must for positioning your laptop’s monitor at eye level. An adjustable stand is preferable to ensure you can adjust it according to your work surface and your height. I have two laptop stands - a stationary one at my desk and one for travel.\nThe two stands in the photo are the Roost (on the left) and iLevel2 by RainDesign (on the right):\n Roost Laptop Stand - I love this stand. It started as a Kickstarter project and an updated version came out several years ago. That team did a great job on the product - it’s lightweight while still being very sturdy. It also has three height options. I’m 5’7” / 170 cm and I use the middle setting, so it is suitable for taller or shorter people as well. There are some cheaper imitations out there (Nextand is the most obvious one) which should also get the job done. Rain Design iLevel2 - I use this stand at my desk and it’s pretty nice. It’s obviously not as mobile, but it looks good and is cheaper than the Roost. My only complaint is that even at the maximum setting, the laptop doesn’t reach eye level. For me, this is not the end of the world since I use it to complement my external monitor. However, if it’s your main screen and you are my height or taller, I’d consider a different option.  And then there’s the third option, which I used at hotel rooms while traveling prior to purchasing the Roost stand - a stack of books/drawers/pillows. It’s not the most elegant or sophisticated, but it costs $0, you don’t have to wait for shipping, and finally - it’s your home office, so no co-worker can judge you on your low-tech frugal setup.\n3. External Mouse and Keyboard Using a laptop stand pretty much forces you to use an external mouse and keyboard, otherwise your forearms and wrists will end up at a really weird angle that will cause more harm than using the laptop on a desk. Of course, an ergonomic set is better, but most of us probably have a mouse and keyboard lying around somewhere. If not, a simple wired or even wireless mouse and keyboard combo can be purchased for $20 or less.\nThe mouse I use for travel is a very simple HP mouse that I bought eight years ago while living in France. I picked it up at a local tech store for about 5€. There’s nothing fancy about it other than the fact that it’s the perfect size to just stick in a bag and not take up a lot of space.\nThe keyboard I have is a Bluetooth keyboard by iClever. It is an ergonomic portable keyboard, which is a really hard thing to find. It can connect to up to three devices and works with Windows, Mac, iOS and Android. Plus, when folded it takes only a little more space than my iPhone X: 4. Headsets (Optional) These are not a must but will make your working from home experience a lot easier.\n Headset with noise cancelling microphone - Even though you’re at home, noise can still be an issue. My previous apartment was on a main street not far from a hospital. At least five times a day, police cars, ambulances and fire trucks would pass next to my building with sirens blazing. I got used to it very quickly, but it did tend to startle people on conference calls and make them think I was living in a war zone. After using the basic iPhone headset for several years, I purchased the Plantronics 5200 following a recommendation from one of my customers. It’s designed to be a travel headset, but I use it all the time as my main headset. It integrates with Zoom, Teams and Skype, plus the noise cancellation technology on the microphone is excellent. I have had calls while walking down a windy and busy Chicago street and those on the call had no problems hearing me. Noise cancelling headphones - As mentioned, the noise at home can be a real distraction, especially if you do not live alone. I use over-the-ear Bluetooth headphones that I picked up from Amazon for $40 two years ago. They don’t have active noise cancellation, but they tune out enough noise for me to focus and still hear if someone calls to me from the other room.  In conclusion, for very little effort and potentially little (to no) cost, you can greatly improve your working from home experience. If you have any ideas for ways to improve your temporary home/mobile office, would like to share your setup, or have any feedback, please comment or send me an email.\nDisclaimer: this post was not sponsored by any of the mentioned products. I am simply sharing my own opinions and experiences.\n","date":1585008011,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585008011,"objectID":"1920914c1d1db3f15472e25af7b58327","permalink":"https://softwaredefinedcoffee.com/post/2020-03-23-equipment-for-temporary-working-from-home/","publishdate":"2020-03-23T19:00:11-05:00","relpermalink":"/post/2020-03-23-equipment-for-temporary-working-from-home/","section":"post","summary":"As more people are working from home due to COVID-19, I’ve seen plenty of remote-working resources and tips being shared across social media and other platforms. The Virtually Speaking Podcast did a great episode about it recently. Most of these resources discuss the changes both the employee and employer must make regarding communication, productivity, and culture change. If you are not accustomed to working remotely, then maintaining visual communication and avoiding distractions will take time to get used to and incorporate into your daily routine. While these skills are extremely important and can feel overwhelming when you are thrown into the situation on short notice, it is also essential to keep basic ergonomics in mind.","tags":["Work From Home","Business Travel"],"title":"Tips for a Mobile or Temporary Home Office Setup","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"bc4392f1ea547748b24346e4b7211190","permalink":"https://softwaredefinedcoffee.com/vcdx/vcdx-mocks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/vcdx/vcdx-mocks/","section":"vcdx","summary":"","tags":null,"title":"VCDX Mock Design Scenarios","type":"widget_page"}]